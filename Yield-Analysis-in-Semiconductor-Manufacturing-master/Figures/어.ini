어
06. imbalance data 해결 방법 
    oversampling
-필요한 이유 : 수십만 건 중에 한 개의 오류가 있을 경우 적은 수의 클래스 분포를 
 재대로 학습하지 못하고 모델이 Majority에 과적합된다. 하지만 Minority 중요한
 클래스이기 때문에 잘 학습시킬 필요가 있다. 이때 사용하는 방법이 oversampling
 (minotiry의 수가 매우 적기 때문에 언더 샘플링은 잘 안함)
1. random over sampling(ROS)
 기존 소수의 클래스를 단순 복제하여 비율을 맞추는 것>숫자를 늘려서 더 많은 가중치를
 받게 하는 방법
 단순 데이터 복제라 성능이 좋지 않을 것 같지만, 실험적으로는 유효할 때가 있음
 똑같은 데이터를 증식시키기 때문에 overfitting의 위험이 있음
2. Sythetic Minority Over-Sampling Technique(SMOTE)
 소수 클래스 데이터로부터 인근 소수 클래스 사이에 새로운 데이터를 생성하는 것
 거의 모든 oversampling에 사용됨

-제품의 결함, 손실 같은 Minority 클래스를 구분할 때 필요한 데이터 전처리이기때문에
 중요함.
(참고  : https://wyatt37.tistory.com/10)


08. ROC 커브를 이용한 모델 평가
 ROC 커브 : 분류모델이 알맞게 예측했는지에 대해 그래프로 표현한 것.
분류 모델에서는 결과가 Y일 확률 또는 점수를 게산하고 점수가 특정 기준을 넘으면Y, 
넘지 않으면 N 으로 예측값을 출력한다.
예시
 1  0.97    Y
 2  0.86    Y
 3  0.75    N
 4  0.71    N
 5  0.66    Y
일때 TP(맞는것을 맞다고 예측:Y) 와 FP(틀린것을 맞다고 예측:X)에 대한 그래프를 그림
점선은 50%확률, 만약 점선보다 그래프가 밑에 있다면 랜덤하게 고객을 분류하는것보다
못한 알고리즘이고, 점선보다 그래프가 위로 그려지면 좋은 알고리즘이라 할 수 있다.
(맞는것은 맞다고 예측하고, 틀린것을 맞다고 예측하지 않는다는 뜻.)
AUC는 ROC 커브 밑의 넓이고
AUC가 
0.9~1 : excellent
0.8~0.9 : good
0.7~0.8 : normal
0.6~0.7 : poor
0.5~0.6 : fail
이라고 할 수 있다.

-모델 성능을 평가할 때 유용하게 쓰임으로 다양한 모델을 만든 후 성능을 평가해서
최적의 모델을 찾을 때 쓸 수 있다.
(참고 : https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=tjdudwo93&logNo=221046150588)


02. 데이터 전처리
Scaling : 데이터 분포의 모양을 유지한채로 동일한 비율로 범위를 조정하는 것
Standardization : 표준 편차를 1로 맞추기 위해 데이터 가공
Regularization: 가중치를 조정할 때 추가적인 제약을 주는 것

(참고 : https://blog.nerdfactory.ai/2021/06/15/Normalization-Theorem-1.html)